{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhjFtaTQhI72LSRLIUEAbg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sp246uF7obPC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2791,"status":"ok","timestamp":1710290579394,"user":{"displayName":"Maahum Jahangir","userId":"05214197111980906799"},"user_tz":420},"id":"C4fHfM9LIjPI","outputId":"78a77b3b-53ef-417f-aced-ea13c267ad5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGc3VHrJLVkJ"},"outputs":[],"source":["TRAINING_PATH = '/content/drive/Shareddrives/1:1_Maahum_Jahangir/Train'\n","VALIDATION_PATH = '/content/drive/Shareddrives/1:1_Maahum_Jahangir/Validation'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQu1247VLYVm"},"outputs":[],"source":["def create_model(base_model, num_classes):\n","    import tensorflow as tf\n","    # Grab the last layer and add a few extra layers to it\n","    x=base_model.output\n","    x=GlobalAveragePooling2D()(x)\n","    # Dense layer 1\n","    x=tf.keras.layers.Dense(100,activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=True)(x)\n","\n","    # Final layer with softmax activation\n","    preds=tf.keras.layers.Dense(num_classes,activation='softmax', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=False)(x)\n","\n","    # Create the final model\n","    model=Model(inputs=base_model.input,outputs=preds)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImwhTDLyMDWL"},"outputs":[],"source":["def get_optimizer(optimizer_name, learning_rate):\n","    # Import keras optimizers\n","    from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, Ftrl, Nadam, RMSprop, SGD\n","    print('Selected Optimizer', optimizer_name)\n","    switcher = {\n","        'Adadelta': Adadelta(learning_rate=learning_rate),\n","        'Adagrad': Adagrad(learning_rate=learning_rate),\n","        'Adam': Adam(learning_rate=learning_rate),\n","        'Adamax': Adamax(learning_rate=learning_rate),\n","        'FTRL': Ftrl(learning_rate=learning_rate),\n","        'NAdam': Nadam(learning_rate=learning_rate),\n","        'RMSprop': RMSprop(learning_rate=learning_rate),\n","        'Gradient Descent': SGD(learning_rate=learning_rate)\n","    }\n","    # If optimizer_name is empty, Adam will be return as default optimizer\n","    return switcher.get(optimizer_name, Adam(learning_rate=learning_rate))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hhXoDXa4MRx4","outputId":"d761bd10-ced8-4fe7-a801-4402b248cb81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2492 images belonging to 3 classes.\n","Found 306 images belonging to 3 classes.\n","dict_keys(['glioma', 'meningioma', 'pituitary_tumor'])\n","175\n","Selected Optimizer Adam\n","Epoch 1/50\n","78/78 [==============================] - 35s 414ms/step - loss: 1.2911 - accuracy: 0.3038 - val_loss: 1.2774 - val_accuracy: 0.3039\n","Epoch 2/50\n","78/78 [==============================] - 31s 395ms/step - loss: 1.2620 - accuracy: 0.3038 - val_loss: 1.2491 - val_accuracy: 0.3039\n","Epoch 3/50\n","78/78 [==============================] - 32s 404ms/step - loss: 1.2352 - accuracy: 0.3038 - val_loss: 1.2233 - val_accuracy: 0.3039\n","Epoch 4/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.2108 - accuracy: 0.3038 - val_loss: 1.1998 - val_accuracy: 0.3039\n","Epoch 5/50\n","78/78 [==============================] - 31s 396ms/step - loss: 1.1888 - accuracy: 0.3038 - val_loss: 1.1791 - val_accuracy: 0.3039\n","Epoch 6/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.1696 - accuracy: 0.3038 - val_loss: 1.1605 - val_accuracy: 0.3039\n","Epoch 7/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.1528 - accuracy: 0.3038 - val_loss: 1.1448 - val_accuracy: 0.3039\n","Epoch 8/50\n","78/78 [==============================] - 31s 399ms/step - loss: 1.1383 - accuracy: 0.3038 - val_loss: 1.1309 - val_accuracy: 0.3039\n","Epoch 9/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.1256 - accuracy: 0.3038 - val_loss: 1.1190 - val_accuracy: 0.3039\n","Epoch 10/50\n","78/78 [==============================] - 31s 393ms/step - loss: 1.1144 - accuracy: 0.3038 - val_loss: 1.1080 - val_accuracy: 0.3039\n","Epoch 11/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.1044 - accuracy: 0.3038 - val_loss: 1.0986 - val_accuracy: 0.3039\n","Epoch 12/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0959 - accuracy: 0.3038 - val_loss: 1.0909 - val_accuracy: 0.3039\n","Epoch 13/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0887 - accuracy: 0.3038 - val_loss: 1.0841 - val_accuracy: 0.3039\n","Epoch 14/50\n","78/78 [==============================] - 31s 398ms/step - loss: 1.0825 - accuracy: 0.3150 - val_loss: 1.0782 - val_accuracy: 0.3431\n","Epoch 15/50\n","78/78 [==============================] - 31s 393ms/step - loss: 1.0772 - accuracy: 0.4422 - val_loss: 1.0732 - val_accuracy: 0.5294\n","Epoch 16/50\n","78/78 [==============================] - 31s 396ms/step - loss: 1.0725 - accuracy: 0.5602 - val_loss: 1.0690 - val_accuracy: 0.5686\n","Epoch 17/50\n","78/78 [==============================] - 31s 399ms/step - loss: 1.0686 - accuracy: 0.5333 - val_loss: 1.0654 - val_accuracy: 0.5098\n","Epoch 18/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.0653 - accuracy: 0.4924 - val_loss: 1.0623 - val_accuracy: 0.4902\n","Epoch 19/50\n","78/78 [==============================] - 32s 407ms/step - loss: 1.0624 - accuracy: 0.4743 - val_loss: 1.0596 - val_accuracy: 0.4739\n","Epoch 20/50\n","78/78 [==============================] - 31s 399ms/step - loss: 1.0600 - accuracy: 0.4675 - val_loss: 1.0575 - val_accuracy: 0.4706\n","Epoch 21/50\n","78/78 [==============================] - 32s 406ms/step - loss: 1.0579 - accuracy: 0.4659 - val_loss: 1.0555 - val_accuracy: 0.4706\n","Epoch 22/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0561 - accuracy: 0.4655 - val_loss: 1.0539 - val_accuracy: 0.4673\n","Epoch 23/50\n","78/78 [==============================] - 32s 405ms/step - loss: 1.0546 - accuracy: 0.4655 - val_loss: 1.0526 - val_accuracy: 0.4673\n","Epoch 24/50\n","78/78 [==============================] - 31s 398ms/step - loss: 1.0533 - accuracy: 0.4655 - val_loss: 1.0513 - val_accuracy: 0.4673\n","Epoch 25/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0522 - accuracy: 0.4655 - val_loss: 1.0503 - val_accuracy: 0.4673\n","Epoch 26/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0511 - accuracy: 0.4655 - val_loss: 1.0494 - val_accuracy: 0.4673\n","Epoch 27/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0503 - accuracy: 0.4655 - val_loss: 1.0487 - val_accuracy: 0.4673\n","Epoch 28/50\n","78/78 [==============================] - 31s 394ms/step - loss: 1.0495 - accuracy: 0.4655 - val_loss: 1.0480 - val_accuracy: 0.4673\n","Epoch 29/50\n","78/78 [==============================] - 31s 395ms/step - loss: 1.0488 - accuracy: 0.4655 - val_loss: 1.0474 - val_accuracy: 0.4673\n","Epoch 30/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.0483 - accuracy: 0.4655 - val_loss: 1.0468 - val_accuracy: 0.4673\n","Epoch 31/50\n","78/78 [==============================] - 31s 400ms/step - loss: 1.0477 - accuracy: 0.4655 - val_loss: 1.0463 - val_accuracy: 0.4673\n","Epoch 32/50\n","78/78 [==============================] - 31s 396ms/step - loss: 1.0472 - accuracy: 0.4655 - val_loss: 1.0459 - val_accuracy: 0.4673\n","Epoch 33/50\n","78/78 [==============================] - 32s 407ms/step - loss: 1.0468 - accuracy: 0.4655 - val_loss: 1.0455 - val_accuracy: 0.4673\n","Epoch 34/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0463 - accuracy: 0.4655 - val_loss: 1.0451 - val_accuracy: 0.4673\n","Epoch 35/50\n","78/78 [==============================] - 32s 405ms/step - loss: 1.0460 - accuracy: 0.4655 - val_loss: 1.0448 - val_accuracy: 0.4673\n","Epoch 36/50\n","78/78 [==============================] - 31s 403ms/step - loss: 1.0456 - accuracy: 0.4655 - val_loss: 1.0445 - val_accuracy: 0.4673\n","Epoch 37/50\n","78/78 [==============================] - 31s 399ms/step - loss: 1.0453 - accuracy: 0.4655 - val_loss: 1.0441 - val_accuracy: 0.4673\n","Epoch 38/50\n","78/78 [==============================] - 31s 400ms/step - loss: 1.0450 - accuracy: 0.4655 - val_loss: 1.0438 - val_accuracy: 0.4673\n","Epoch 39/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0447 - accuracy: 0.4655 - val_loss: 1.0436 - val_accuracy: 0.4673\n","Epoch 40/50\n","78/78 [==============================] - 31s 400ms/step - loss: 1.0444 - accuracy: 0.4655 - val_loss: 1.0433 - val_accuracy: 0.4673\n","Epoch 41/50\n","78/78 [==============================] - 30s 391ms/step - loss: 1.0441 - accuracy: 0.4655 - val_loss: 1.0430 - val_accuracy: 0.4673\n","Epoch 42/50\n","78/78 [==============================] - 31s 397ms/step - loss: 1.0438 - accuracy: 0.4655 - val_loss: 1.0428 - val_accuracy: 0.4673\n","Epoch 43/50\n","78/78 [==============================] - 31s 403ms/step - loss: 1.0435 - accuracy: 0.4655 - val_loss: 1.0425 - val_accuracy: 0.4673\n","Epoch 44/50\n","78/78 [==============================] - 31s 396ms/step - loss: 1.0433 - accuracy: 0.4655 - val_loss: 1.0423 - val_accuracy: 0.4673\n","Epoch 45/50\n","78/78 [==============================] - 31s 399ms/step - loss: 1.0430 - accuracy: 0.4655 - val_loss: 1.0420 - val_accuracy: 0.4673\n","Epoch 46/50\n","78/78 [==============================] - 31s 398ms/step - loss: 1.0427 - accuracy: 0.4655 - val_loss: 1.0417 - val_accuracy: 0.4673\n","Epoch 47/50\n","78/78 [==============================] - 31s 401ms/step - loss: 1.0424 - accuracy: 0.4655 - val_loss: 1.0415 - val_accuracy: 0.4673\n","Epoch 48/50\n","78/78 [==============================] - 31s 403ms/step - loss: 1.0422 - accuracy: 0.4655 - val_loss: 1.0412 - val_accuracy: 0.4673\n","Epoch 49/50\n","78/78 [==============================] - 31s 398ms/step - loss: 1.0419 - accuracy: 0.4655 - val_loss: 1.0410 - val_accuracy: 0.4673\n","Epoch 50/50\n","78/78 [==============================] - 31s 396ms/step - loss: 1.0416 - accuracy: 0.4655 - val_loss: 1.0407 - val_accuracy: 0.4673\n"]}],"source":["\n","# Import packages needed to create a image classification model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import tensorflow as tf\n","\n","from keras.applications.mobilenet_v2 import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense,GlobalAveragePooling2D\n","from keras.models import Model\n","from tensorflow.keras import regularizers\n","\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from keras.callbacks import EarlyStopping\n","from tensorflow import keras\n","\n","# Initialize hyper params\n","epochs = 50 #<-- increase for higher accuracy\n","base_learning_rate = 0.000001 #decrease for different results; use excel sheet to note down results from each change to learning rate and epochs\n","optimizer = 'Adam'\n","BATCH_SIZE = 32\n","\n","IMG_SIZE = (224, 224)\n","\n","# Create the data generation pipeline for training and validation\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","train_generator = train_datagen.flow_from_directory(TRAINING_PATH,\n","                                                target_size=IMG_SIZE,\n","                                                color_mode='rgb',\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical',\n","                                                shuffle=True,\n","                                                )\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_PATH,\n","                                                target_size=IMG_SIZE,\n","                                                color_mode='rgb',\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical',\n","                                                shuffle=True,\n","                                                )\n","\n","print(validation_generator.class_indices.keys())\n","# Download the model, valid alpha values [0.25,0.35,0.5,0.75,1]\n","base_model = tf.keras.applications.ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n","for layer in base_model.layers:\n","    layer.trainable=False\n","\n","# Specify the number of classes\n","num_classes = 3\n","\n","# Create the base model\n","model = create_model(base_model,num_classes)\n","\n","print(len(base_model.layers))\n","\n","model.compile(optimizer = get_optimizer(optimizer_name=optimizer,learning_rate=base_learning_rate),loss='CategoricalCrossentropy',metrics=['accuracy'])\n","# Adam optimizer\n","# loss function will be categorical cross entropy\n","# evaluation metric will be accuracy\n","\n","early_stopping_monitor = EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=30,\n","    verbose=0,\n","    mode='auto',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","\n","step_size_train = train_generator.n//train_generator.batch_size\n","history_fine = model.fit(train_generator,\n","                        epochs=epochs,\n","                        validation_data = validation_generator,\n","                        verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0Vz6dZwNjwX"},"outputs":[],"source":["def visualization():\n","    import pandas as pd\n","    df = pd.DataFrame(history_fine.history)\n","    #loss plots\n","    plt.figure(figsize=(8,8))\n","    plt.plot(df['loss'], color='red', label = \"Training_loss\")\n","    plt.plot(df['val_loss'], color='blue')\n","    plt.legend(['Training Loss','Validation loss'],loc = 'best' )\n","    plt.title('Line plot of Training and Validation loss')\n","    plt.ylim(0,1)\n","    plt.show()\n","\n","    #accuracy plots\n","    plt.figure(figsize=(8,8))\n","    plt.plot(df['accuracy'], color='red')\n","    plt.plot(df['val_accuracy'], color='blue')\n","    plt.legend(['Training acc','Validation acc'],loc = 'best' )\n","    plt.title('Line plot of Training and Validation Accuracies')\n","    plt.ylim(0,1)\n","    plt.show()\n","\n","visualization()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezP6uOlzNx-4"},"outputs":[],"source":["\n","# Import numpy for calculating best model accuracy\n","import numpy as np\n","# Populating matrics -> accuracy & loss\n","acc = history_fine.history['accuracy']\n","val_acc = history_fine.history['val_accuracy']\n","\n","loss = history_fine.history['loss']\n","val_loss = history_fine.history['val_loss']\n","\n","print('Training Accuracy: ', acc)\n","print('Validation Accuracy: ', val_acc)\n","print('Training Loss: ', loss)\n","print('Validation Loss: ', val_loss)\n","best_model_accuracy = history_fine.history['val_accuracy'][np.argmin(history_fine.history['val_loss'])]\n","print('best model accuracy: ', best_model_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-xXFNkANyrz"},"outputs":[],"source":["def seperate_labels(generator):\n","    x_validation = []\n","    y_validation = []\n","    num_seen = 0\n","\n","    for x, labels in generator:\n","        x_validation.append(x)\n","        y_validation.append([argmax(label) for label in labels])\n","        num_seen += len(x)\n","        if num_seen == generator.n: break\n","\n","    x_validation = np.concatenate(x_validation)\n","    y_validation = np.concatenate(y_validation)\n","    return x_validation, y_validation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNY9jmGBN0yE"},"outputs":[],"source":["\n","# Calculate and display the confusion matrix\n","import matplotlib.pyplot as plt\n","from numpy.core.fromnumeric import argmax\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","x_validation, y_validation = seperate_labels(validation_generator)\n","y_pred = model.predict(x_validation, batch_size=BATCH_SIZE)\n","predictions = np.apply_along_axis(argmax, 1, y_pred)\n","display_labels = validation_generator.class_indices.keys()\n","\n","# ConfusionMatrixDisplay.from_predictions(y_validation, predictions, display_labels=display_labels, cmap=\"binary\")\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ti68xdP0N2yj"},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","plt.figure(figsize = (10,10))\n","sns.heatmap(confusion_matrix(y_validation, predictions), annot = True, fmt = 'g', cmap = \"Blues\",xticklabels=display_labels, yticklabels=display_labels)\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTiCxI9COf2B"},"outputs":[],"source":["print(classification_report(y_validation, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCwrqeUHOh8L"},"outputs":[],"source":["\n","# Predicting code for an image\n","from tensorflow.keras.preprocessing import image\n","# Please replace the brackets below with the location of your image which need to predict\n","img_path = '/content/drive/Shareddrives/1:1_Maahum_Jahangir/Test/glioma/1883.png'\n","img = image.load_img(img_path, target_size=IMG_SIZE)\n","img_array = image.img_to_array(img)\n","img_batch = np.expand_dims(img_array, axis=0)\n","img_preprocessed = preprocess_input(img_batch)\n","prediction = model.predict(img_preprocessed)\n","print(prediction)\n"]}]}